{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(([3,5],[5,1],[10,2]),dtype = float)\n",
    "y = np.array(([75],[82],[93]), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  5.],\n",
       "       [ 5.,  1.],\n",
       "       [10.,  2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.],\n",
       "       [82.],\n",
       "       [93.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Data\n",
    "x = x/np.amax(x, axis = 0)\n",
    "y = y/100 # max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        #define HyperParameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Wights (Parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        \n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Propagate inputs through network\n",
    "        self.z2 = np.dot(x,self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2,self.W2)\n",
    "        yHat = self.sigmoid(self.z3)\n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "    #Apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "    #Derivative of Sigmoid Function\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self,x,y):\n",
    "        #compute cost for given x, y, use weights already stored in calss\n",
    "        self.yHat = self.forward(x)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "    \n",
    "    def costFunctionPrime(self,x,y):\n",
    "    #compute derivative with respect to W1 and W2, for a given x and y\n",
    "        self.yHat = self.forward(x)\n",
    "    \n",
    "        delta3 = np.multiply(-(y-self.yHat),self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "\n",
    "        delta2 = np.dot(delta3,self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(x.T,delta2)\n",
    "\n",
    "        return dJdW1, dJdW2\n",
    "      \n",
    "\n",
    "    def getParams(self):\n",
    "        #get W1 and W2 rooled into vector:\n",
    "        \n",
    "        params = np.concatenate((self.W1.ravel(),self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self,params):\n",
    "        #Set W1 and W2 using single parameter vector:\n",
    "        \n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize*self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], \\\n",
    "                             (self.inputLayerSize,self.hiddenLayerSize))\n",
    "        \n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end],\\\n",
    "                            (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, x, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(x,y)\n",
    "            \n",
    "        return np.concatenate((dJdW1.ravel(),dJdW2.ravel()))\n",
    "    \n",
    "    def computeNumericalGradient(N,x,y):\n",
    "        paramsInitial = N.getParams()\n",
    "        numgrad = np.zeros(paramsInitial.shape)\n",
    "        perturb = np.zeros(paramsInitial.shape)\n",
    "        e = 1e-4\n",
    "        \n",
    "        for p in range(len(paramsInitial)):\n",
    "            #set perturbation vector\n",
    "            perturb[p] = e\n",
    "            N.setParams(paramsInitial + perturb)\n",
    "            loss2 = N.costFunction(x,y)\n",
    "            \n",
    "            N.setParams(paramsInitial - perturb)\n",
    "            loss1  =N.costFunction(x, y)\n",
    "            \n",
    "            #computer numerical gradient:\n",
    "            \n",
    "            numgrad[p] = (loss2-loss1)/(2*e)\n",
    "            \n",
    "            #return the value of changed back to zero:\n",
    "            \n",
    "            perturn[p]=0\n",
    "            \n",
    "        #Return params to original value\n",
    "        \n",
    "        N.setParams(paramsInitial)\n",
    "        \n",
    "        return numgrad\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def computeNumericalGradient(N,x,y):\n",
    "#         paramsInitial = N.getParams()\n",
    "#         numgrad = np.zeros(paramsInitial.shape)\n",
    "#         perturb = np.zeros(paramsInitial.shape)\n",
    "#         e = 1e-4\n",
    "        \n",
    "#         for p in range(len(paramsInitial)):\n",
    "#             #set perturbation vector\n",
    "#             perturb[p] = e\n",
    "#             N.setParams(paramsInitial + perturb)\n",
    "#             loss2 = N.costFunction(x,y)\n",
    "            \n",
    "#             N.setParams(paramsInitial - perturb)\n",
    "#             loss1  =N.costFunction(x, y)\n",
    "            \n",
    "#             #computer numerical gradient:\n",
    "            \n",
    "#             numgrad[p] = (loss2-loss1)/(2*e)\n",
    "            \n",
    "#             #return the value of changed back to zero:\n",
    "            \n",
    "#             perturn[p]=0\n",
    "            \n",
    "#         #Return params to original value\n",
    "        \n",
    "#         N.setParams(paramsInitial)\n",
    "        \n",
    "#         return numgrad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()\n",
    "# # numgrad = NN.computeNumericalGradient(NN,x,y)\n",
    "# grad = NN.computeGradients(x,y)\n",
    "# grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yHat = NN.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70702151],\n",
       "       [0.71649047],\n",
       "       [0.74765656]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our Estimate\n",
    "yHat = NN.forward(x)\n",
    "yHat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual Data\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "class trainer(object):\n",
    "    def __init__(self,N):\n",
    "        #make local reference to Neural Netowrk\n",
    "        self.N = N\n",
    "        \n",
    "    def costFunctionWrapper(self,params,x,y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(x,y)\n",
    "        grad = self.N.computeGradients(x,y)\n",
    "        return cost,grad\n",
    "    \n",
    "    def callbackF(self,params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.x,self.y))\n",
    "        \n",
    "        \n",
    "    def train(self,x,y):\n",
    "        #make internal variables for call back function: \n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        #make emptry list to store costs:\n",
    "        self.J = []\n",
    "        \n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "        \n",
    "        options = {'maxiter' : 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper,params0, \\\n",
    "                                jac = True, method = 'BFGS', args = (x,y),\\\n",
    "                                options = options, callback=self.callbackF)\n",
    "        \n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 63\n",
      "         Function evaluations: 66\n",
      "         Gradient evaluations: 66\n"
     ]
    }
   ],
   "source": [
    "T = trainer(NN)\n",
    "T.train(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iteration')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(T.J)\n",
    "plt.grid()\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iteration')\n",
    "# print(T.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-6.49590312e-08,  3.78988386e-08,  9.35313599e-09],\n",
       "        [-3.95097041e-07,  2.41474568e-07,  4.82838570e-08]]),\n",
       " array([[1.46091765e-07],\n",
       "        [2.08497529e-07],\n",
       "        [2.06543281e-07]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.costFunctionPrime(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75000256],\n",
       "       [0.81999987],\n",
       "       [0.92999778]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test network for various combinations of sleep/study:\n",
    "hoursSleep = np.linspace(0,10,100)\n",
    "hoursStudy = np.linspace(0,5,100)\n",
    "\n",
    "#Normalize data (same way)\n",
    "hoursStudyNorm = hoursSleep/10.\n",
    "hoursStudyNorm = hoursStudy/5.\n",
    "\n",
    "#Create 2-d versions of input for plotting\n",
    "\n",
    "a, b = np.meshgrid(hoursStudyNorm,hoursStudyNorm)\n",
    "\n",
    "#join into a single input matrix:\n",
    "\n",
    "allInputs = np.zeros((a.size,2))\n",
    "allInputs[:,0] = a.ravel()\n",
    "allInputs[:,1] = b.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "allOutputs = NN.forward(allInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a list of 6 text.Text objects>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make Contour Plot\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "yy = np.dot(hoursStudy.reshape(100,1),np.ones((1,100)))\n",
    "\n",
    "xx = np.dot(hoursSleep.reshape(100,1),np.ones((1,100))).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.label(CS,incline = 1, fontsize = 10)\n",
    "\n",
    "plt.xlabel('Hours Sleep')\n",
    "plt.ylabel('Hours Study')\n",
    "\n",
    "\n",
    "CS = plt.contour(xx,yy,100.*allOutputs.reshape(100,100))\n",
    "plt.clabel(CS, inline = 1, fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make3D plot\n",
    "%matplotlib qt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.gca(projection = '3d')\n",
    "\n",
    "\n",
    "surf = ax.plot_surface(xx,yy,100*allOutputs.reshape(100,100), \\\n",
    "                      cmap = plt.cm.jet)\n",
    "\n",
    "ax.set_xlabel ('Hours Sleep')\n",
    "ax.set_ylabel('Hours Study')\n",
    "ax.set_zlabel('Test Score')\n",
    "plt.gca().invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
